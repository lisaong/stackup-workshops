{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      y                                                  X\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/SMSSpamCollection', delimiter='\\t', header=None, names=['y', 'X'])\n",
    "\n",
    "# Show the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count how many of each category\n",
    "df.y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into training and test sets\n",
    "\n",
    "Test set is set aside for independent testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     3618\n",
      "spam     561\n",
      "Name: y, dtype: int64\n",
      "ham     1207\n",
      "spam     186\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# shuffle and split the corpus into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.X, df.y, random_state=42)\n",
    "\n",
    "# Count how many of each category for training and test sets\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process text data to extract features\n",
    "\n",
    "- Tokenize by spaces\n",
    "- Remove stop words\n",
    "- Convert each word into its count (how many times the word appears in the corpus)\n",
    "- Usage of uppercase is common in spam messages, we will preserve the case by setting lowercase=False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4179x9329 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 56614 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(lowercase=False)\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "Z_train = vectorizer.transform(X_train)\n",
    "Z_test = vectorizer.transform(X_test)\n",
    "\n",
    "Z_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1393x9329 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 16839 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Naive Bayes classifier\n",
    "\n",
    "Naive Bayes classfiers are generally a good first start for a simple classification model. \n",
    "\n",
    "This computes probabilities of spam vs. ham using a Gaussian distribution.\n",
    "\n",
    "$$\n",
    "P(x_i \\mid y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_y}} \\exp\\left(-\\frac{(x_i - \\mu_y)^2}{2\\sigma^2_y}\\right)\n",
    "$$\n",
    "\n",
    "http://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9267767408470926\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(Z_train.toarray(), y_train)\n",
    "\n",
    "print('Accuracy', clf.score(Z_test.toarray(), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1121,   86],\n",
       "       [  16,  170]], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = clf.predict(Z_test.toarray())\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy looks good (92.7%) for the test set, but in reality the number of misclassified \"spam\" is relatively high.\n",
    "\n",
    "```\n",
    "array([[1121,  86],\n",
    "       [  16,  170]], dtype=int64)\n",
    "```\n",
    "\n",
    "- 1121 = number of correctly classified 'ham' SMS\n",
    "- 170 = number of correctly classified 'spam' SMS\n",
    "- 16 = number of 'spam' wrongly classified as 'ham'\n",
    "- 86 = number of 'ham' wrongly classified as 'spam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting error cases\n",
    "\n",
    "Let's take a look at some of the incorrectly labelled cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "881     Reminder: You have not downloaded the content ...\n",
       "3864    Oh my god! I've found your number again! I'm s...\n",
       "2402    Babe: U want me dont u baby! Im nasty and have...\n",
       "4527    I want some cock! My hubby's away, I need a re...\n",
       "2663    Hello darling how are you today? I would love ...\n",
       "751     Do you realize that in about 40 years, we'll h...\n",
       "3463    Bloomberg -Message center +447797706009 Why wa...\n",
       "1126    For taking part in our mobile survey yesterday...\n",
       "227     Will u meet ur dream partner soon? Is ur caree...\n",
       "3755    Bloomberg -Message center +447797706009 Why wa...\n",
       "856     Talk sexy!! Make new friends or fall in love i...\n",
       "3360    Sorry I missed your call let's talk when you h...\n",
       "2770    Burger King - Wanna play footy at a top stadiu...\n",
       "731     Email AlertFrom: Jeri StewartSize: 2KBSubject:...\n",
       "1507    Thanks for the Vote. Now sing along with the s...\n",
       "68      Did you hear about the new \"Divorce Barbie\"? I...\n",
       "Name: X, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_classified_as_ham = X_test[(y_test == 'spam') & (y_test != y_pred)]\n",
    "\n",
    "spam_classified_as_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1859                     Sir, i am waiting for your call.\n",
       "2952                     Hey now am free you can call me.\n",
       "3142                       Customer place i will call you\n",
       "2422    Err... Cud do. I'm going to  at 8pm. I haven't...\n",
       "4937                             K..k.:)congratulation ..\n",
       "5519    Can you pls send me that company name. In saib...\n",
       "5339                  You'd like that wouldn't you? Jerk!\n",
       "315             You made my day. Do have a great day too.\n",
       "5349                                          I'm home...\n",
       "33      For fear of fainting with the of all that hous...\n",
       "1870                       Mom wants to know where you at\n",
       "4050                     Yeah that's the impression I got\n",
       "2067                           Then. You are eldest know.\n",
       "4677                              Ü ready then call me...\n",
       "3535                           Good evening! How are you?\n",
       "3689                           I'll meet you in the lobby\n",
       "4999                               Can you talk with me..\n",
       "132               Dear, will call Tmorrow.pls accomodate.\n",
       "1837                               Are you wet right now?\n",
       "893     Nutter. Cutter. Ctter. Cttergg. Cttargg. Ctarg...\n",
       "1612                                                  645\n",
       "534                                       I'll be late...\n",
       "3655                     Why i come in between you people\n",
       "1934                              R u over scratching it?\n",
       "889                              You unbelievable faglord\n",
       "2329        That day you asked about anand number. Why:-)\n",
       "3542             If you are not coughing then its nothing\n",
       "4357       Great. So should i send you my account number.\n",
       "1520                Check wid corect speling i.e. Sarcasm\n",
       "5307                              What you did in  leave.\n",
       "                              ...                        \n",
       "2561                     Are you still getting the goods.\n",
       "4796    Saw Guys and Dolls last night with Patrick Swa...\n",
       "69                     I plane to give on this month end.\n",
       "5470                           I thought slide is enough.\n",
       "2899          If you r @ home then come down within 5 min\n",
       "387                       Customer place i will call you.\n",
       "2603                  So when you gonna get rimac access \n",
       "805                             K I'll be there before 4.\n",
       "2107                     Thank you. I like you as well...\n",
       "4886                      Poor girl can't go one day lmao\n",
       "2963             NONE!NOWHERE IKNO DOESDISCOUNT!SHITINNIT\n",
       "2873                                      See you there! \n",
       "1553                                             U too...\n",
       "4293                                                G.W.R\n",
       "2451                              K..give back my thanks.\n",
       "596                              I am great! How are you?\n",
       "2807                                           Can a not?\n",
       "5151    No problem with the renewal. I.ll do it right ...\n",
       "1406                             K..k..any special today?\n",
       "3336            Sorry, got a late start, we're on the way\n",
       "2164    hi my darlin im on my way to London and we hav...\n",
       "4482                         No..its ful of song lyrics..\n",
       "122     here is my new address -apples&pairs&all that ...\n",
       "2298                            Draw va?i dont think so:)\n",
       "1501                   Host-based IDPS for linux systems.\n",
       "3877                               did u get that message\n",
       "1030                           Its good, we'll find a way\n",
       "2197           Not much, just some textin'. How bout you?\n",
       "2173     Yavnt tried yet and never played original either\n",
       "949                              Chk in ur belovd ms dict\n",
       "Name: X, Length: 86, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_classified_as_spam = X_test[(y_test == 'ham') & (y_test != y_pred)]\n",
    "\n",
    "ham_classified_as_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model for deployment\n",
    "\n",
    "We can optimize the model further (for example by using word vectors instead of counts), but for now let's save the model so that we can use it from our web server.\n",
    "\n",
    "Scikit-learn models can be saved using pickle, which is Python's general purpose serialisation library.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/model_persistence.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Serialise the CountVectorizer\n",
    "pickle.dump(vectorizer, open('model/vectorizer.pickle', 'wb'))\n",
    "\n",
    "# Serialize the GaussianNB classifier\n",
    "pickle.dump(clf, open('model/model.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is DATA\n",
      " Volume Serial Number is B200-6E0E\n",
      "\n",
      " Directory of D:\\stackup-workshops\\simple-ml\\model\n",
      "\n",
      "04/10/2018  03:25 PM    <DIR>          .\n",
      "04/10/2018  03:25 PM    <DIR>          ..\n",
      "04/10/2018  03:25 PM           299,209 model.pickle\n",
      "04/10/2018  03:25 PM           399,600 vectorizer.pickle\n",
      "               2 File(s)        698,809 bytes\n",
      "               2 Dir(s)  782,077,120,512 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
